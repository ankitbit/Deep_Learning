{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Product Classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankitbit/Deep_Learning/blob/master/Assignment%20Reports/Assignment%202/Product_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Mg8XMvKaBDHT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "outputId": "1b4a2c91-88fe-48ae-8989-d477063d7c71"
      },
      "cell_type": "code",
      "source": [
        "! wget 'https://raw.githubusercontent.com/ankitbit/Deep_Learning/master/Assignment%20Reports/Assignment%202/data/cameras.tsv'\n",
        "! wget 'https://raw.githubusercontent.com/ankitbit/Deep_Learning/master/Assignment%20Reports/Assignment%202/data/clothing.tsv'\n",
        "! wget 'https://raw.githubusercontent.com/ankitbit/Deep_Learning/master/Assignment%20Reports/Assignment%202/data/home.tsv'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-11-13 05:04:28--  https://raw.githubusercontent.com/ankitbit/Deep_Learning/master/Assignment%20Reports/Assignment%202/data/cameras.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 97776 (95K) [text/plain]\n",
            "Saving to: ‘cameras.tsv’\n",
            "\n",
            "\rcameras.tsv           0%[                    ]       0  --.-KB/s               \rcameras.tsv         100%[===================>]  95.48K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2018-11-13 05:04:28 (5.82 MB/s) - ‘cameras.tsv’ saved [97776/97776]\n",
            "\n",
            "--2018-11-13 05:04:30--  https://raw.githubusercontent.com/ankitbit/Deep_Learning/master/Assignment%20Reports/Assignment%202/data/clothing.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21653659 (21M) [text/plain]\n",
            "Saving to: ‘clothing.tsv’\n",
            "\n",
            "clothing.tsv        100%[===================>]  20.65M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2018-11-13 05:04:32 (172 MB/s) - ‘clothing.tsv’ saved [21653659/21653659]\n",
            "\n",
            "--2018-11-13 05:04:34--  https://raw.githubusercontent.com/ankitbit/Deep_Learning/master/Assignment%20Reports/Assignment%202/data/home.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 657104 (642K) [text/plain]\n",
            "Saving to: ‘home.tsv’\n",
            "\n",
            "home.tsv            100%[===================>] 641.70K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2018-11-13 05:04:35 (22.9 MB/s) - ‘home.tsv’ saved [657104/657104]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eNyghpWVNGn4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "! pip install gensim\n",
        "! pip install nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VIElG7ChLTt9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gensim.models import KeyedVectors\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "MAX_NB_WORDS = 200000\n",
        "MAX_SEQUENCE_LENGTH = 30\n",
        "EMBEDDING_DIM = 300\n",
        "\n",
        "EMBEDDING_FILE = \"GoogleNews-vectors-negative300.bin\"\n",
        "category_index = {\"clothing\":0, \"camera\":1, \"home-appliances\":2}\n",
        "category_reverse_index = dict((y,x) for (x,y) in category_index.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fy1ZbRSPDUBf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "5cc164b1-bd0e-4cb3-b3e6-88ab228e30a9"
      },
      "cell_type": "code",
      "source": [
        "clothing = pd.read_csv(\"clothing.tsv\", sep='\\t')\n",
        "cameras = pd.read_csv(\"cameras.tsv\", sep='\\t')\n",
        "home_appliances = pd.read_csv(\"home.tsv\", sep='\\t')\n",
        "datasets = [clothing, cameras, home_appliances]\n",
        "\n",
        "print(\"Make sure there are no null values in the datasets\")\n",
        "for data in datasets:\n",
        "    print(\"Has null values: \", data.isnull().values.any())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Make sure there are no null values in the datasets\n",
            "Has null values:  False\n",
            "Has null values:  False\n",
            "Has null values:  False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pd-YxrFZDluR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "    text= text.strip().lower().split()\n",
        "    return \" \".join(text)\n",
        "    \n",
        "for dataset in datasets:\n",
        "    dataset['title'] = dataset['title'].apply(preprocess)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Er8nGo0JBIia",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_texts = clothing['title'] + cameras['title'] + home_appliances['title']\n",
        "all_texts = all_texts.drop_duplicates(keep=False)\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
        "tokenizer.fit_on_texts(all_texts)\n",
        "\n",
        "clothing_sequences = tokenizer.texts_to_sequences(clothing['title'])\n",
        "electronics_sequences = tokenizer.texts_to_sequences(cameras['title'])\n",
        "home_appliances_sequences = tokenizer.texts_to_sequences(home_appliances['title'])\n",
        "\n",
        "clothing_data = pad_sequences(clothing_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "electronics_data = pad_sequences(electronics_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "home_appliances_data = pad_sequences(home_appliances_sequences, maxlen=MAX_SEQUENCE_LENGTH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vkX9brybBfS1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "012162be-555f-4195-a637-883a682b4167"
      },
      "cell_type": "code",
      "source": [
        "word_index = tokenizer.word_index\n",
        "test_string = \"sports action spy pen camera\"\n",
        "print(\"word\\t\\tid\")\n",
        "print(\"-\" * 20)\n",
        "for word in test_string.split():\n",
        "    print(\"%s\\t\\t%s\" % (word, word_index[word]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word\t\tid\n",
            "--------------------\n",
            "sports\t\t16\n",
            "action\t\t13\n",
            "spy\t\t7\n",
            "pen\t\t60\n",
            "camera\t\t2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CHGNF4RCBoS1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "fddc49b7-1ef0-41bf-f111-8194119c0cdc"
      },
      "cell_type": "code",
      "source": [
        "test_sequence = tokenizer.texts_to_sequences([\"sports action camera\", \"spy pen camera\"])\n",
        "padded_sequence = pad_sequences(test_sequence, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "print(\"Text to Vector\", test_sequence)\n",
        "print(\"Padded Vector\", padded_sequence)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text to Vector [[16, 13, 2], [7, 60, 2]]\n",
            "Padded Vector [[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0 16 13  2]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  7 60  2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yNfaPiALC5t0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "32ba5bae-a664-4c12-ac67-7dd8be80cb6f"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"clothing: \\t\\t\", to_categorical(category_index[\"clothing\"], 3))\n",
        "print(\"camera: \\t\\t\", to_categorical(category_index[\"camera\"], 3))\n",
        "print(\"home appliances: \\t\", to_categorical(category_index[\"home-appliances\"], 3))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clothing: \t\t [1. 0. 0.]\n",
            "camera: \t\t [0. 1. 0.]\n",
            "home appliances: \t [0. 0. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q3fYKCOBB5zr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "1d92b5dc-dcd8-4ea5-b6ea-222093775d6a"
      },
      "cell_type": "code",
      "source": [
        "print(\"clothing shape: \", clothing_data.shape)\n",
        "print(\"electronics shape: \", electronics_data.shape)\n",
        "print(\"home appliances shape: \", home_appliances_data.shape)\n",
        "\n",
        "data = np.vstack((clothing_data, electronics_data, home_appliances_data))\n",
        "category = pd.concat([clothing['category'], cameras['category'], home_appliances['category']]).values\n",
        "category = to_categorical(category)\n",
        "print(\"-\"*10)\n",
        "print(\"combined data shape: \", data.shape)\n",
        "print(\"combined category/label shape: \", category.shape)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clothing shape:  (392721, 30)\n",
            "electronics shape:  (1347, 30)\n",
            "home appliances shape:  (11425, 30)\n",
            "----------\n",
            "combined data shape:  (405493, 30)\n",
            "combined category/label shape:  (405493, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UJRERjjTOkGw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "VALIDATION_SPLIT = 0.4\n",
        "indices = np.arange(data.shape[0]) # get sequence of row index\n",
        "np.random.shuffle(indices) # shuffle the row indexes\n",
        "data = data[indices] # shuffle data/product-titles/x-axis\n",
        "category = category[indices] # shuffle labels/category/y-axis\n",
        "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
        "x_train = data[:-nb_validation_samples]\n",
        "y_train = category[:-nb_validation_samples]\n",
        "x_val = data[-nb_validation_samples:]\n",
        "y_val = category[-nb_validation_samples:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lUw13fiYfRHh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "b079fe29-d6ff-4d74-f296-ba897ae9939d"
      },
      "cell_type": "code",
      "source": [
        "! wget 'https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz'"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-11-13 05:16:15--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.96.165\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.96.165|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  36.1MB/s    in 44s     \n",
            "\n",
            "2018-11-13 05:17:00 (35.4 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TH6Dt2VdgQL_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! gunzip GoogleNews-vectors-negative300.bin.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SC0nvSCMPO97",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "word2vec = gensim.models.KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GQLBCS2eeACQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ba1c2093-5760-4b9c-d670-fe1cd9490f7f"
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Embedding\n",
        "word_index = tokenizer.word_index\n",
        "nb_words = min(MAX_NB_WORDS, len(word_index))+1\n",
        "\n",
        "embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    if word in word2vec.vocab:\n",
        "        embedding_matrix[i] = word2vec.word_vec(word)\n",
        "print('Null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))\n",
        "\n",
        "embedding_layer = Embedding(embedding_matrix.shape[0], # or len(word_index) + 1\n",
        "                            embedding_matrix.shape[1], # or EMBEDDING_DIM,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,\n",
        "                            trainable=False)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Null word embeddings: 1476\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Qc3zgKIyg-D_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "c4552554-b00e-4b27-92dd-46623b24fde1"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D, Flatten\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(embedding_layer)\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv1D(300, 3, padding='valid',activation='relu',strides=2))\n",
        "model.add(Conv1D(150, 3, padding='valid',activation='relu',strides=2))\n",
        "model.add(Conv1D(75, 3, padding='valid',activation='relu',strides=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(150,activation='sigmoid'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(3,activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['acc'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 30, 300)           822900    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 30, 300)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 14, 300)           270300    \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 6, 150)            135150    \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 2, 75)             33825     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 150)               22650     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 453       \n",
            "=================================================================\n",
            "Total params: 1,285,278\n",
            "Trainable params: 462,378\n",
            "Non-trainable params: 822,900\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TF1PJtWhhGC5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "outputId": "040dcca5-19e6-4c16-8f0b-9346998e0e17"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "model_1 = Sequential()\n",
        "model_1.add(embedding_layer)\n",
        "model_1.add(Conv1D(250,3,padding='valid',activation='relu',strides=1))\n",
        "model_1.add(GlobalMaxPooling1D())\n",
        "model_1.add(Dense(250))\n",
        "model_1.add(Dropout(0.2))\n",
        "model_1.add(Activation('relu'))\n",
        "model_1.add(Dense(3))\n",
        "model_1.add(Activation('sigmoid'))\n",
        "model_1.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['acc'])\n",
        "model_1.summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 30, 300)           822900    \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 28, 250)           225250    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 250)               62750     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3)                 753       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 1,111,653\n",
            "Trainable params: 288,753\n",
            "Non-trainable params: 822,900\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fF_RzJcohKzw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "c101a97f-91de-4ddd-ea9f-49acf718ee19"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=2, batch_size=128)\n",
        "score = model.evaluate(x_val, y_val, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 243296 samples, validate on 162197 samples\n",
            "Epoch 1/2\n",
            "243296/243296 [==============================] - 33s 135us/step - loss: 0.1212 - acc: 0.9726 - val_loss: 0.1064 - val_acc: 0.9773\n",
            "Epoch 2/2\n",
            "243296/243296 [==============================] - 30s 121us/step - loss: 0.1095 - acc: 0.9768 - val_loss: 0.1064 - val_acc: 0.9775\n",
            "Test loss: 0.10636043810499474\n",
            "Test accuracy: 0.9774965011683323\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QM7LdXljhhTf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "5a20e734-fa5d-4a24-b8ad-b0e28a6cebe4"
      },
      "cell_type": "code",
      "source": [
        "model_1.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=2, batch_size=128)\n",
        "score = model_1.evaluate(x_val, y_val, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 243296 samples, validate on 162197 samples\n",
            "Epoch 1/2\n",
            "243296/243296 [==============================] - 20s 81us/step - loss: 0.0031 - acc: 0.9991 - val_loss: 0.0012 - val_acc: 0.9999\n",
            "Epoch 2/2\n",
            "243296/243296 [==============================] - 19s 80us/step - loss: 0.0010 - acc: 0.9999 - val_loss: 0.0015 - val_acc: 0.9997\n",
            "Test loss: 0.0015222370080718018\n",
            "Test accuracy: 0.9997225596034451\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tpuMLcPCh0rb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "1e4ba93c-cdff-4b3e-ccb2-0c05aa7ee36f"
      },
      "cell_type": "code",
      "source": [
        "example_product = \"Nikon Coolpix A10 Point and Shoot (Black)\"\n",
        "example_product = preprocess(example_product)\n",
        "example_sequence = tokenizer.texts_to_sequences([example_product])\n",
        "example_padded_sequence = pad_sequences(example_sequence, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "print(\"-\"*10)\n",
        "print(\"Predicted category: \", category_reverse_index[model_1.predict_classes(example_padded_sequence, verbose=0)[0]])\n",
        "print(\"-\"*10)\n",
        "probabilities = model_1.predict(example_padded_sequence, verbose=0)\n",
        "probabilities = probabilities[0]\n",
        "print(\"Clothing Probability: \",probabilities[category_index[\"clothing\"]] )\n",
        "print(\"Camera Probability: \",probabilities[category_index[\"camera\"]] )\n",
        "print(\"home appliances probability: \",probabilities[category_index[\"home-appliances\"]] )"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------\n",
            "Predicted category:  camera\n",
            "----------\n",
            "Clothing Probability:  3.3783804e-10\n",
            "Camera Probability:  0.14272517\n",
            "home appliances probability:  0.0002004157\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}