{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Machine_Translation_Attention.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankitbit/Deep_Learning/blob/master/Assignment%20Reports/Assignment%203/Neural_Machine_Translation_Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "4MrILrhumMUi",
        "colab_type": "code",
        "outputId": "d61d3bc4-9665-41bd-ce91-0b14914a8cb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "! wget 'http://www.manythings.org/anki/spa-eng.zip'\n",
        "! unzip spa-eng.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-12-18 21:30:11--  http://www.manythings.org/anki/spa-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 104.24.109.196, 104.24.108.196, 2606:4700:30::6818:6dc4, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|104.24.109.196|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2819791 (2.7M) [application/zip]\n",
            "Saving to: ‘spa-eng.zip’\n",
            "\n",
            "spa-eng.zip         100%[===================>]   2.69M   169KB/s    in 15s     \n",
            "\n",
            "2018-12-18 21:30:32 (178 KB/s) - ‘spa-eng.zip’ saved [2819791/2819791]\n",
            "\n",
            "Archive:  spa-eng.zip\n",
            "  inflating: _about.txt              \n",
            "  inflating: spa.txt                 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7a3rRnTbmiDZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! mkdir 'data/'\n",
        "! mv 'spa.txt' 'data/spa-eng.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yQYv9JPoh5CA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QAPprV6mh9nl",
        "colab_type": "code",
        "outputId": "dc9db00e-1467-4e7b-8a0b-0b8c0e6d1f44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "cell_type": "code",
      "source": [
        "! pip install torch"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/60/66415660aa46b23b5e1b72bc762e816736ce8d7260213e22365af51e8f9c/torch-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (591.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 591.8MB 26kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x60d8e000 @  0x7f52818402a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "Successfully installed torch-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZoqmxFIDiMgp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d8cb2235-68ee-406b-da78-52bfca73149e"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device used:\",device)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device used: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ag3HKRlVhMaR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZNndYQWKg0Vy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q42k9Tu-hHgI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# http://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W0CGM9krhKUm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pkmsfHtHhNI_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s\",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[1].startswith(eng_prefixes)\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1sb9wjPMhTZl",
        "colab_type": "code",
        "outputId": "5b3ea4e7-526f-48c2-acfb-caf06d67706d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "cell_type": "code",
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('spa', 'eng', True)\n",
        "print(random.choice(pairs))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "Read 120614 sentence pairs\n",
            "Trimmed to 7755 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "eng 4036\n",
            "spa 2836\n",
            "['es como de la familia .', 'you re like family .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tOL2P1S4ie3H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tTVpwO2biiCc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HzRAWms_ilta",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "einU07FJio3V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3DMkwadbitFx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EM06TIFgiv38",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f21_Ulbtizoi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.1):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9bhFiePWi2Ds",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qo718Ypji5-v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2A9rQqd7i7Gu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PPQleK-Hi9Mi",
        "colab_type": "code",
        "outputId": "f9c2496f-4842-40a9-e5fa-12161cf69f04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1378
        }
      },
      "cell_type": "code",
      "source": [
        "hidden_size = 64\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "trainIters(encoder1, attn_decoder1, 60000, print_every=1000)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0m 52s (- 51m 43s) (1000 1%) 3.5528\n",
            "1m 35s (- 45m 57s) (2000 3%) 3.0970\n",
            "2m 18s (- 43m 49s) (3000 5%) 3.0373\n",
            "3m 1s (- 42m 22s) (4000 6%) 3.0246\n",
            "3m 44s (- 41m 14s) (5000 8%) 3.0937\n",
            "4m 28s (- 40m 13s) (6000 10%) 3.0093\n",
            "5m 11s (- 39m 17s) (7000 11%) 2.9951\n",
            "5m 54s (- 38m 23s) (8000 13%) 3.1036\n",
            "6m 37s (- 37m 33s) (9000 15%) 3.0180\n",
            "7m 21s (- 36m 48s) (10000 16%) 2.9991\n",
            "8m 3s (- 35m 53s) (11000 18%) 4.3720\n",
            "8m 45s (- 35m 1s) (12000 20%) 4.3170\n",
            "9m 27s (- 34m 10s) (13000 21%) 4.7237\n",
            "10m 8s (- 33m 19s) (14000 23%) 4.8627\n",
            "10m 50s (- 32m 30s) (15000 25%) 4.8879\n",
            "11m 32s (- 31m 43s) (16000 26%) 4.8579\n",
            "12m 13s (- 30m 55s) (17000 28%) 4.6914\n",
            "12m 54s (- 30m 8s) (18000 30%) 4.6524\n",
            "13m 36s (- 29m 21s) (19000 31%) 4.8577\n",
            "14m 17s (- 28m 34s) (20000 33%) 4.9205\n",
            "14m 59s (- 27m 49s) (21000 35%) 5.5970\n",
            "15m 40s (- 27m 4s) (22000 36%) 6.0247\n",
            "16m 22s (- 26m 21s) (23000 38%) 5.3815\n",
            "17m 4s (- 25m 36s) (24000 40%) 5.5673\n",
            "17m 44s (- 24m 50s) (25000 41%) 6.1225\n",
            "18m 26s (- 24m 6s) (26000 43%) 5.9839\n",
            "19m 8s (- 23m 23s) (27000 45%) 5.9665\n",
            "19m 50s (- 22m 40s) (28000 46%) 6.2755\n",
            "20m 31s (- 21m 56s) (29000 48%) 6.5808\n",
            "21m 13s (- 21m 13s) (30000 50%) 6.8196\n",
            "21m 54s (- 20m 29s) (31000 51%) 6.3188\n",
            "22m 34s (- 19m 45s) (32000 53%) 6.4347\n",
            "23m 15s (- 19m 2s) (33000 55%) 6.2277\n",
            "23m 57s (- 18m 19s) (34000 56%) 6.4586\n",
            "24m 38s (- 17m 36s) (35000 58%) 6.5176\n",
            "25m 20s (- 16m 53s) (36000 60%) 6.2999\n",
            "26m 1s (- 16m 10s) (37000 61%) 6.4762\n",
            "26m 42s (- 15m 27s) (38000 63%) 6.6451\n",
            "27m 23s (- 14m 45s) (39000 65%) 6.5223\n",
            "28m 5s (- 14m 2s) (40000 66%) 6.8687\n",
            "28m 46s (- 13m 20s) (41000 68%) 6.9987\n",
            "29m 28s (- 12m 37s) (42000 70%) 7.0654\n",
            "30m 9s (- 11m 55s) (43000 71%) 7.0006\n",
            "30m 51s (- 11m 13s) (44000 73%) 7.2678\n",
            "31m 33s (- 10m 31s) (45000 75%) 7.0776\n",
            "32m 15s (- 9m 49s) (46000 76%) 7.3222\n",
            "32m 57s (- 9m 6s) (47000 78%) 7.5715\n",
            "33m 39s (- 8m 24s) (48000 80%) 7.5194\n",
            "34m 21s (- 7m 42s) (49000 81%) 7.7312\n",
            "35m 3s (- 7m 0s) (50000 83%) 7.7146\n",
            "35m 44s (- 6m 18s) (51000 85%) 7.5450\n",
            "36m 26s (- 5m 36s) (52000 86%) 7.4966\n",
            "37m 8s (- 4m 54s) (53000 88%) 7.8035\n",
            "37m 50s (- 4m 12s) (54000 90%) 7.7016\n",
            "38m 31s (- 3m 30s) (55000 91%) 7.1409\n",
            "39m 13s (- 2m 48s) (56000 93%) 7.0354\n",
            "39m 53s (- 2m 5s) (57000 95%) 6.8027\n",
            "40m 35s (- 1m 23s) (58000 96%) 6.7723\n",
            "41m 17s (- 0m 41s) (59000 98%) 6.9916\n",
            "41m 58s (- 0m 0s) (60000 100%) 7.0765\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-b50ab63e9a5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mencoder1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_lang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mattn_decoder1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttnDecoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_decoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-e2c30a0882d0>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(encoder, decoder, n_iters, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mplot_loss_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mshowPlot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'showPlot' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "7zeNsQUilZ0m",
        "colab_type": "code",
        "outputId": "31178a9a-1dd1-4890-df69-d08e57c100bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        }
      },
      "cell_type": "code",
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> no depende de sus padres .\n",
            "= he is independent of his parents .\n",
            "< i m not the of of . <EOS>\n",
            "\n",
            "> me temo que tengo hemorragia interna .\n",
            "= i m afraid i have internal bleeding .\n",
            "< i m afraid of you will . <EOS>\n",
            "\n",
            "> estoy satisfecho que tu todavia recuerdes .\n",
            "= i m pleased you still remember .\n",
            "< i m sure you your your . <EOS>\n",
            "\n",
            "> no estoy escribiendo una carta .\n",
            "= i am not writing a letter .\n",
            "< i m not a a a a <EOS>\n",
            "\n",
            "> estoy intrigada .\n",
            "= i m intrigued .\n",
            "< i m sick . <EOS>\n",
            "\n",
            "> somos personas ocupadas .\n",
            "= we re busy men .\n",
            "< we re all . . <EOS>\n",
            "\n",
            "> estamos todos de acuerdo .\n",
            "= we are all in agreement .\n",
            "< we re all in . <EOS>\n",
            "\n",
            "> soy japones .\n",
            "= i am japanese .\n",
            "< i m japanese . <EOS>\n",
            "\n",
            "> has venido pronto a casa .\n",
            "= you re home early .\n",
            "< you are safe to home . <EOS>\n",
            "\n",
            "> me estas interrumpiendo .\n",
            "= you re interrupting me .\n",
            "< you re all me . <EOS>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0BTdIYonlcuL",
        "colab_type": "code",
        "outputId": "2906d9d1-617d-4585-e335-0902887aa3f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "cell_type": "code",
      "source": [
        "# Evaluation of attention\n",
        "%matplotlib inline\n",
        "output_words, attentions = evaluate(\n",
        "    encoder1, attn_decoder1, \"como estas .\")\n",
        "plt.matshow(attentions.numpy())"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa1413d0198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdkAAAD+CAYAAAB2mX84AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFgCGiCwADBFZABjy/4DGaV6rbRHNAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fa14139e8d0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "RE7HbY-jmBBX",
        "colab_type": "code",
        "outputId": "259102ae-975d-4ecc-f290-a549b636acbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "cell_type": "code",
      "source": [
        "def showAttention(input_sentence, output_words, attentions):\n",
        "    # Set up figure with colorbar\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    # Set up axes\n",
        "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
        "                       ['<EOS>'], rotation=90)\n",
        "    ax.set_yticklabels([''] + output_words)\n",
        "\n",
        "    # Show label at every tick\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def evaluateAndShowAttention(input_sentence):\n",
        "    output_words, attentions = evaluate(\n",
        "        encoder1, attn_decoder1, input_sentence)\n",
        "    print('input =', input_sentence)\n",
        "    print('output =', ' '.join(output_words))\n",
        "    showAttention(input_sentence, output_words, attentions)\n",
        "\n",
        "\n",
        "evaluateAndShowAttention(\"ella es joven\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input = ella es joven\n",
            "output = she is young . <EOS>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAADnCAYAAAAD+N1NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fa140fd58d0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "XiWIAY7VJJQw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "150d6c49-13d1-4cc7-f33c-9e4f941f4459"
      },
      "cell_type": "code",
      "source": [
        "from nltk.bleu_score"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.11.0)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}